{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import textwrap\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Â Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Neo4J Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local Neo4J database\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\")\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = PDFPlumberLoader(\"data/ISBANK2023.pdf\")\n",
    "# docs = loader.load()\n",
    "# text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
    "# documents = text_splitter.split_documents(docs)\n",
    "# # Check the number of pages\n",
    "# print(\"Number of pages in the PDF:\",len(docs))\n",
    "# print(\"Number of documents after chunking:\",len(documents))\n",
    "\n",
    "# # # Merge multiple documents into a single input for unified graph generation\n",
    "# # combined_content = \"\\n\\n\".join([doc.page_content for doc in documents[50:100]]) \n",
    "# # combined_content = [Document(page_content=combined_content)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in documents:\n",
    "#     if \"\\n\" in doc.page_content:\n",
    "#         print(doc)\n",
    "#         doc.page_content = doc.page_content.replace(\"\\n\", \"\")\n",
    "\n",
    "# for i, doc in enumerate(documents):\n",
    "#     if len(doc.page_content) <= 10:\n",
    "#         documents.pop(i)\n",
    "\n",
    "# print(\"Number of pages in the PDF:\",len(docs))\n",
    "# print(\"Number of documents after chunking:\",len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_text = \"\"\"\n",
    "Umut Can Gulsen, born in 1998, was a Turkish and naturalised-French physicist and chemist who conducted pioneering research on quantum physics.\n",
    "He was the first man to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields. His husband, Pierre Gulsen, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "He was, in 200, the first man to become a professor at the University of Paris. \n",
    "\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "She was, in 1906, the first woman to become a professor at the University of Paris. \n",
    "\"\"\"\n",
    "# Convert the text into documents\n",
    "documents = [Document(page_content=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model for text-to-graph conversion\n",
    "llm = ChatOllama(model=\"llama3\", temperature=0)\n",
    "llm_transformer_filtered = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert multiple text documents into graph structures\n",
    "# graph_documents = []\n",
    "# for doc in docs[:10]:  # Iterate over multiple documents\n",
    "#     graph_documents.extend(llm_transformer_filtered.convert_to_graph_documents([doc]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text into graph documents\n",
    "graph_documents = llm_transformer_filtered.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GraphDocument(nodes=[Node(id='1867', type='Year', properties={}), Node(id='Curie family', type='Family', properties={}), Node(id='Marie Curie', type='Person', properties={}), Node(id='Nobel Prize', type='Award', properties={}), Node(id='University of Paris', type='Institution', properties={}), Node(id='None', type='None', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='radioactivity', type='Field of Study', properties={})], relationships=[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='1867', type='Year', properties={}), type='BORN_IN', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='radioactivity', type='Field of Study', properties={}), type='WORKED_ON', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WON_AWARD', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='None', type='None', properties={}), type='WON_AWARD_TWICE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='None', type='None', properties={}), type='WON_AWARD_IN_TWO_FIELDS', properties={}), Relationship(source=Node(id='Pierre Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='CO_WINNER_OF', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University of Paris', type='Institution', properties={}), type='BECAME_PROFESSOR', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Curie family', type='Family', properties={}), type='LAUNCHED_LEGACY', properties={})], source=Document(metadata={}, page_content='\\nMarie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\\nShe was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\\nHer husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\\nShe was, in 1906, the first woman to become a professor at the University of Paris. \\n'))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='1867', type='Year', properties={}), Node(id='Curie family', type='Family', properties={}), Node(id='Marie Curie', type='Person', properties={}), Node(id='Nobel Prize', type='Award', properties={}), Node(id='University of Paris', type='Institution', properties={}), Node(id='None', type='None', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='radioactivity', type='Field of Study', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='1867', type='Year', properties={}), type='BORN_IN', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='radioactivity', type='Field of Study', properties={}), type='WORKED_ON', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WON_AWARD', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='None', type='None', properties={}), type='WON_AWARD_TWICE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='None', type='None', properties={}), type='WON_AWARD_IN_TWO_FIELDS', properties={}), Relationship(source=Node(id='Pierre Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='CO_WINNER_OF', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University of Paris', type='Institution', properties={}), type='BECAME_PROFESSOR', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Curie family', type='Family', properties={}), type='LAUNCHED_LEGACY', properties={})]\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "print(f\"Nodes:{graph_documents[ix].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[ix].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher = \"\"\"\n",
    "MATCH (n)\n",
    "DETACH DELETE n\n",
    "\"\"\"\n",
    "graph.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the generated graph into Neo4j\n",
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Solution: \n",
    "#### Use GraphCypherQAChain to generate Cypher queries and return response from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "Schema:\n",
    "{schema}\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "Examples: Here are a few examples of generated Cypher statements for particular questions:\n",
    "\n",
    "# Who is Michael Scott?\n",
    "MATCH (person:Person)-[:WON_AWARD]->(award:Award)\n",
    "    WHERE person.id = 'Michael Scott'\n",
    "RETURN person.id, award.id\n",
    "\n",
    "# Who won the award?\n",
    "MATCH (person:Person)-[:WON_AWARD]->(award:Award)\n",
    "    WHERE person.id = 'Michael Scott'\n",
    "RETURN person.id, award.id\n",
    "\n",
    "# What kind of research does Michael conduct?\n",
    "  MATCH (person:Person)-[:WORKED_ON]->(field:'Field of Study')\n",
    "    WHERE person.id = 'Michael Scott'\n",
    "  RETURN person.id, field.id\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "\n",
    "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], \n",
    "    template=CYPHER_GENERATION_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3\")\n",
    "chain = GraphCypherQAChain.from_llm(graph=graph, \n",
    "                                    llm=llm, \n",
    "                                    verbose=True, \n",
    "                                    allow_dangerous_requests=True, \n",
    "                                    # return_intermediate_steps=True, \n",
    "                                    # return_direct=True, \n",
    "                                    cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
    "                                    )\n",
    "# response = chain.invoke({\"query\": \"Who is Pierre Curie?\"})\n",
    "\n",
    "def prettyCypherChain(question: str) -> str:\n",
    "    response = chain.run(question)\n",
    "    print(textwrap.fill(response, 60))\n",
    "\n",
    "# # To check the generated query manually\n",
    "# cypher = \"\"\"\n",
    "# MATCH (person:Person)-[:WON_AWARD]->(award:Award) \n",
    "# WHERE person.id = 'Marie Curie' \n",
    "# RETURN person.id, award.id\n",
    "# \"\"\"\n",
    "# graph.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (person:Person)-[:WORKED_ON]->(field) \n",
      "WHERE person.id = 'Marie Curie' \n",
      "RETURN person.id, field.id\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'person.id': 'Marie Curie', 'field.id': 'radioactivity'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "radioactivity.\n"
     ]
    }
   ],
   "source": [
    "prettyCypherChain(\"What is Marie Curie's primary research field?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longer Solution: \n",
    "#### Create a retriever from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for more complex search queries\n",
    "embed = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embedding=embed,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "vector_retriever = vector_index.as_retriever()\n",
    "\n",
    "# Define a model for the extracted entities from the text\n",
    "class Entities(BaseModel):\n",
    "    names: list[str] = Field(..., description=\"All entities from the text\")\n",
    "\n",
    "# Define a prompt to extract entities from the input query\n",
    "prompt = ChatPromptTemplate.from_messages([ \n",
    "    (\"system\", \"Extract organization and person entities from the text.\"),\n",
    "    (\"human\", \"Extract entities from: {question}\")\n",
    "])\n",
    "\n",
    "# Initialize the Ollama model for entity extraction with LLM (using \"llama3\")\n",
    "llm = OllamaFunctions(model=\"llama3\", format=\"json\", temperature=0.4)\n",
    "\n",
    "# Combine the prompt and LLM to create an entity extraction chain\n",
    "# The output is structured to match the \"Entities\" model\n",
    "entity_chain = prompt | llm.with_structured_output(Entities, include_raw=True)\n",
    "\n",
    "# Function to retrieve relationships of the extracted entities from Neo4j\n",
    "def graph_retriever(question: str) -> str:\n",
    "    # Use the entity extraction chain to get entities from the question\n",
    "    response = entity_chain.invoke({\"question\": question})\n",
    "    # Extract the list of entity names from the response\n",
    "    entities = response['raw'].tool_calls[0]['args']['properties']['names']\n",
    "    print(\"-\"*30)\n",
    "    print(\"Retreived Entities\")\n",
    "    print(entities)\n",
    "    result = \"\"  # Initialize a variable to store the result\n",
    "\n",
    "    # Iterate over each extracted entity\n",
    "    for entity in entities:\n",
    "        # Query Neo4j to get relationships for the given entity\n",
    "        query_response = graph.query(\n",
    "            \"\"\"MATCH (p:Person {id: $entity})-[r]->(e)\n",
    "            RETURN p.id AS source_id, type(r) AS relationship, e.id AS target_id\n",
    "            LIMIT 50\"\"\",\n",
    "            {\"entity\": entity}\n",
    "        )\n",
    "        # Format the query results and append to the result string\n",
    "        result += \"\\n\".join([f\"{el['source_id']} - {el['relationship']} -> {el['target_id']}\" for el in query_response])+ \"\\n\"\n",
    "    \n",
    "    # Return the formatted results containing entity relationships\n",
    "    return result\n",
    "\n",
    "def full_retriever(question: str):\n",
    "    # Retrieve graph data for the question using the graph_retriever function\n",
    "    graph_data = graph_retriever(question)\n",
    "    print(\"-\"*30)\n",
    "    print(\"Graph Data\")\n",
    "    print(graph_data)\n",
    "    # Retrieve vector data by invoking the vector retriever with the question\n",
    "    vector_data = [el.page_content for el in vector_retriever.invoke(question)]\n",
    "    # Retrieve vector-based data for multiple documents\n",
    "    # vector_results = vector_retriever.invoke(question)\n",
    "    #vector_data = \"\\n\".join([f\"#Document {i+1}: {el.page_content}\" for i, el in enumerate(vector_results)])\n",
    "    print(\"-\"*30)\n",
    "    print(\"Vector Data\")\n",
    "    print(vector_data)\n",
    "    print(\"-\"*30)\n",
    "    # Combine the graph data and vector data into a formatted string\n",
    "    return f\"Graph data: {graph_data}\\nVector data: {'#Document '.join(vector_data)}\"\n",
    "\n",
    "# Define a prompt template for generating a response based on context\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Create a prompt from the template, which takes the context and question as input\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Create a processing chain that:\n",
    "# 1. Generates context using the full_retriever function\n",
    "# 2. Passes through the question as-is using RunnablePassthrough\n",
    "# 3. Applies the prompt template to generate the final question\n",
    "# 4. Uses the LLM (language model) to generate the answer\n",
    "# 5. Uses StrOutputParser to format the output as a string\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": lambda input: full_retriever(input),  # Generate context from the question\n",
    "        \"question\": RunnablePassthrough(),  # Pass the question through without modification\n",
    "    }\n",
    "    | prompt  # Apply the prompt template\n",
    "    | llm  # Use the language model to answer the question based on context\n",
    "    | StrOutputParser()  # Parse the model's response as a string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Retreived Entities\n",
      "['Umut Can Gulsen']\n",
      "------------------------------\n",
      "Graph Data\n",
      "Umut Can Gulsen - BECAME_PROFESSOR_AT -> University of Paris\n",
      "Umut Can Gulsen - WON_AWARD -> Nobel Prize\n",
      "Umut Can Gulsen - WORKED_ON -> quantum physics\n",
      "Umut Can Gulsen - BORN_IN -> 1998\n",
      "\n",
      "------------------------------\n",
      "Vector Data\n",
      "['\\ntext: \\nUmut Can Gulsen, born in 1998, was a Turkish and naturalised-French physicist and chemist who conducted pioneering research on quantum physics.\\nHe was the first man to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields. His husband, Pierre Gulsen, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\\nHe was, in 200, the first man to become a professor at the University of Paris. \\n']\n",
      "------------------------------\n",
      "Final Answer\n",
      "Umut Can Gulsen is a Turkish and naturalised-French physicist and chemist who conducted pioneering research on quantum physics. He was the first man to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n"
     ]
    }
   ],
   "source": [
    "# Test the chain with a question\n",
    "response = chain.invoke(input=\"Who is Umut Can Gulsen?\")\n",
    "print(\"Final Answer\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
